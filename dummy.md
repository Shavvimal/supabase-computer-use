Based on the logs that need to be saved in your code, here is the SQL to set up the necessary tables in your Supabase (PostgreSQL) database. These tables are designed to store:
User queries
Solutions generated by the agent
Conversation messages exchanged
Tool usage data
Screenshots metadata 2. Create the queries Table
This table stores user queries along with their embeddings and metadata.
CREATE TABLE queries (
id SERIAL PRIMARY KEY,
user_id INTEGER NOT NULL,
query_text TEXT NOT NULL,
query_embedding VECTOR(1536),
type SMALLINT,
created_at TIMESTAMPTZ DEFAULT NOW()
);
Fields:
id: Unique identifier for each query.
user_id: References the user who made the query.
query_text: The text of the user's query.
query_embedding: Vector representation of the query (adjust the dimension if needed).
type: Represents the category or mode of the query.
created_at: Timestamp of when the query was made. 3. Create the solutions Table
This table stores solutions linked to queries, including feedback and conversation data.
CREATE TABLE solutions (
id SERIAL PRIMARY KEY,
query_id INTEGER REFERENCES queries(id) NOT NULL,
feedback JSONB,
conversation_data JSONB,
created_at TIMESTAMPTZ DEFAULT NOW()
);
Fields:
id: Unique identifier for each solution.
query_id: Foreign key linking to the queries table.
feedback: User feedback or evaluation metrics in JSONB format.
conversation_data: Additional conversation data in JSONB format.
created_at: Timestamp of when the solution was generated. 4. Create the conversation_messages Table
This table records each message exchanged during the conversation between the user and the assistant.
CREATE TABLE conversation_messages (
id SERIAL PRIMARY KEY,
solution_id INTEGER REFERENCES solutions(id),
sender TEXT NOT NULL, -- 'user', 'assistant', or 'system'
message_content TEXT NOT NULL,
created_at TIMESTAMPTZ DEFAULT NOW()
);
Fields:
id: Unique identifier for each message.
solution_id: Foreign key linking to the solutions table.
sender: Indicates who sent the message ('user', 'assistant', or 'system').
message_content: The content of the message.
created_at: Timestamp of when the message was sent. 5. Create the tools_used Table
This table logs each tool that was used during the solution process, including inputs and outputs.
CREATE TABLE tools_used (
id SERIAL PRIMARY KEY,
solution_id INTEGER REFERENCES solutions(id),
tool_name TEXT NOT NULL,
tool_input JSONB,
tool_output JSONB,
created_at TIMESTAMPTZ DEFAULT NOW()
);
Fields:
id: Unique identifier for each tool usage record.
solution_id: Foreign key linking to the solutions table.
tool_name: Name of the tool used.
tool_input: Input parameters for the tool in JSONB format.
tool_output: Output from the tool in JSONB format (includes output, error, base64_image).
created_at: Timestamp of when the tool was used. 6. Create the screenshots Table
This table stores URIs of screenshots taken during the solution process. The actual screenshot files will be stored in Supabase Storage.
CREATE TABLE screenshots (
id SERIAL PRIMARY KEY,
solution_id INTEGER REFERENCES solutions(id),
uri TEXT NOT NULL,
created_at TIMESTAMPTZ DEFAULT NOW()
);
Fields:
id: Unique identifier for each screenshot.
solution_id: Foreign key linking to the solutions table.
uri: URI pointing to the screenshot in Supabase Storage.
created_at: Timestamp of when the screenshot was taken. 7. (Optional) Indexes on Embeddings
To optimize similarity searches on embeddings, you can create indexes on the vector fields.
-- Index on query embeddings for faster similarity searches
CREATE INDEX idx_queries_embedding ON queries USING ivfflat (query_embedding);

-- Note: Adjust the parameters of the index (like lists, probes) based on your use case. 8. Additional Considerations
Foreign Key Constraints: Ensure that foreign key relationships are properly enforced, which helps maintain data integrity.
Data Types:Vector Dimensions: Adjust the vector dimensions (VECTOR(1536)) according to the size of your embeddings.
JSONB Fields: Used for feedback, conversation_data, tool_input, and tool_output to store structured data.
Timestamp with Time Zone: Using TIMESTAMPTZ ensures that timestamps are stored with time zone information. 9. Complete SQL Setup
Here is the complete SQL script:
-- Enable the vector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Create the queries table
CREATE TABLE queries (
id SERIAL PRIMARY KEY,
user_id INTEGER NOT NULL,
query_text TEXT NOT NULL,
query_embedding VECTOR(1536),
type SMALLINT,
created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Create the solutions table
CREATE TABLE solutions (
id SERIAL PRIMARY KEY,
query_id INTEGER REFERENCES queries(id) NOT NULL,
feedback JSONB,
conversation_data JSONB,
created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Create the conversation_messages table
CREATE TABLE conversation_messages (
id SERIAL PRIMARY KEY,
solution_id INTEGER REFERENCES solutions(id),
sender TEXT NOT NULL,
message_content TEXT NOT NULL,
created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Create the tools_used table
CREATE TABLE tools_used (
id SERIAL PRIMARY KEY,
solution_id INTEGER REFERENCES solutions(id),
tool_name TEXT NOT NULL,
tool_input JSONB,
tool_output JSONB,
created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Create the screenshots table
CREATE TABLE screenshots (
id SERIAL PRIMARY KEY,
solution_id INTEGER REFERENCES solutions(id),
uri TEXT NOT NULL,
created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Optional: Create indexes on embeddings for faster searches
CREATE INDEX idx_queries_embedding ON queries USING ivfflat (query_embedding); 10. Integrating with Your Code
The tables above align with the data being saved in your code. Ensure that:
Data Formats Match: The data types in your code (e.g., embeddings, JSON structures) are compatible with the corresponding fields in the database.
Foreign Keys: When inserting data, the foreign key fields (query_id, solution_id) must reference existing records in their respective tables.
Error Handling: Implement error handling in your code to catch any exceptions during database operations. 11. Summary of Tables and Their Relationships
queries: Stores user queries with embeddings.
solutions: Each solution is linked to a query (query_id).
conversation_messages: Messages are linked to a solution (solution_id).
tools_used: Tool usage records are linked to a solution (solution_id).
screenshots: Screenshots are linked to a solution (solution_id). 12. Example Data Insertion
When logging data from your code, ensure you insert records in the correct order to maintain foreign key relationships. For example:
Insert into queries to get query_id.
Insert into solutions using query_id to get solution_id.
Insert into conversation_messages, tools_used, and screenshots using solution_id. 13. Adjustments Based on Your Application
If your application requires additional fields or tables, adjust the SQL accordingly. For example:
User Table: If you have a users table, you can add a foreign key constraint on user_id in the queries table.
ALTER TABLE queries
ADD CONSTRAINT fk_user
FOREIGN KEY (user_id)
REFERENCES users(id);
Metadata Fields: You can add more fields to store additional metadata as needed. 14. Final Notes
Testing: After setting up the tables, test the data insertion and retrieval to ensure everything works as expected.
Performance Tuning: Depending on the volume of data and query patterns, consider adding more indexes or optimizing existing ones.
Security: Ensure that your database permissions and security settings prevent unauthorized access.
By creating these tables and integrating the Supabase client calls into your code, you'll be able to store comprehensive logs of user interactions, queries, solutions, tool usage, and more, as per your application's needs.
Let me know if you need further assistance or have any questions about setting up these tables!

####

Given this schema, generate the SQL for pupulating dummy flows. Generate one for:

"How do i enable PGVector"

Enable the extension#

Dashboard

SQL
Go to the Database page in the Dashboard.
Click on Extensions in the sidebar.
Search for "vector" and enable the extension.

Add one for "how do i import via Supabase":

Option 1: CSV import via Supabase dashboard#
Supabase dashboard provides a user-friendly way to import data. However, for very large datasets, this method may not be the most efficient choice, given the size limit is 100MB. It's generally better suited for smaller datasets and quick data imports. Consider using alternative methods like pgloader for large-scale data imports.

Navigate to the relevant table in the Table Editor.
Click on “Insert” then choose "Import Data from CSV" and follow the on-screen instructions to upload your CSV file.
